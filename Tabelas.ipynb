{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importador de Dados ANS para PostgreSQL\n",
    "\n",
    "Este notebook permite importar diferentes datasets da ANS para um banco de dados PostgreSQL.\n",
    "Você pode configurar o diretório dos arquivos, a tabela de destino e outras opções conforme necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação das Dependências\n",
    "\n",
    "Primeiro, vamos instalar os pacotes necessários caso não estejam disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: psycopg2-binary in ./.venv/lib/python3.13/site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in ./.venv/lib/python3.13/site-packages (2.0.39)\n",
      "Requirement already satisfied: ipython-sql in ./.venv/lib/python3.13/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.13/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: prettytable in ./.venv/lib/python3.13/site-packages (from ipython-sql) (3.15.1)\n",
      "Requirement already satisfied: ipython in ./.venv/lib/python3.13/site-packages (from ipython-sql) (9.0.2)\n",
      "Requirement already satisfied: sqlparse in ./.venv/lib/python3.13/site-packages (from ipython-sql) (0.5.3)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.13/site-packages (from ipython-sql) (1.17.0)\n",
      "Requirement already satisfied: ipython-genutils in ./.venv/lib/python3.13/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data->ipython->ipython-sql) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data->ipython->ipython-sql) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data->ipython->ipython-sql) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instalação dos pacotes necessários\n",
    "!pip install pandas psycopg2-binary sqlalchemy ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de conexão com o banco de dados\n",
    "db_config = {\n",
    "    'host': '146.235.222.230',  \n",
    "    'port': '5432',\n",
    "    'database': 'ans',\n",
    "    'user': 'vcollos',\n",
    "    'password': 'Essaaqui:#01'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Conexão e Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    \"\"\"Cria conexão com o banco de dados PostgreSQL\"\"\"\n",
    "    try:\n",
    "        # Conexão via psycopg2 para executar comandos SQL diretos\n",
    "        conn = psycopg2.connect(\n",
    "            host=db_config['host'],\n",
    "            port=db_config['port'],\n",
    "            database=db_config['database'],\n",
    "            user=db_config['user'],\n",
    "            password=db_config['password']\n",
    "        )\n",
    "        print(\"Conexão com PostgreSQL estabelecida com sucesso!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao conectar ao PostgreSQL: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_sqlalchemy_engine():\n",
    "    \"\"\"Cria engine SQLAlchemy para operações com pandas\"\"\"\n",
    "    conn_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "    return create_engine(conn_string)\n",
    "\n",
    "def check_table_exists(conn, table_name):\n",
    "    \"\"\"Verifica se a tabela já existe no banco de dados\"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT EXISTS (\n",
    "                SELECT FROM information_schema.tables \n",
    "                WHERE table_schema = 'public'\n",
    "                AND table_name = %s\n",
    "            );\n",
    "        \"\"\", (table_name,))\n",
    "        exists = cursor.fetchone()[0]\n",
    "        return exists\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar se a tabela existe: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(file_path, sep=';', encoding='utf-8', date_columns=None):\n",
    "    \"\"\"Lê um arquivo CSV usando pandas\"\"\"\n",
    "    try:\n",
    "        # Lendo CSV com o separador especificado\n",
    "        df = pd.read_csv(file_path, sep=sep, encoding=encoding, low_memory=False)\n",
    "        file_name = os.path.basename(file_path)\n",
    "        print(f\"Arquivo {file_name} lido com sucesso. {len(df)} registros encontrados.\")\n",
    "        \n",
    "        # Convertendo colunas de data para o formato correto (se especificadas)\n",
    "        if date_columns:\n",
    "            for col in date_columns:\n",
    "                if col in df.columns:\n",
    "                    # Converter para datetime, lidar com valores vazios\n",
    "                    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler arquivo {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def import_data(df, engine, table_name, if_exists='append'):\n",
    "    \"\"\"Importa os dados do DataFrame para a tabela PostgreSQL\"\"\"\n",
    "    try:\n",
    "        # Importando dados via to_sql do pandas\n",
    "        df.to_sql(table_name, engine, if_exists=if_exists, index=False, schema='public')\n",
    "        print(f\"Dados importados com sucesso para a tabela '{table_name}'! {len(df)} registros inseridos.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao importar dados para a tabela '{table_name}': {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importador Flexível\n",
    "\n",
    "Esta função permite importar qualquer conjunto de arquivos para qualquer tabela no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importar_dados(dir_path, file_pattern, table_name, date_columns=None, \n",
    "                   exclude_files=None, sep=';', encoding='utf-8', if_exists='append', \n",
    "                   create_if_not_exists=True):\n",
    "    \"\"\"Função flexível para importar dados de múltiplos arquivos para uma tabela específica\"\"\"\n",
    "    # Estabelecer conexão com o banco\n",
    "    conn = create_connection()\n",
    "    if not conn:\n",
    "        return\n",
    "    \n",
    "    # Criar engine SQLAlchemy\n",
    "    engine = create_sqlalchemy_engine()\n",
    "    \n",
    "    # Verificar se a tabela existe\n",
    "    tabela_existe = check_table_exists(conn, table_name)\n",
    "    print(f\"Tabela '{table_name}' existe: {tabela_existe}\")\n",
    "    \n",
    "    # Obter todos os arquivos CSV no diretório que seguem o padrão\n",
    "    csv_files = glob.glob(os.path.join(dir_path, file_pattern))\n",
    "    \n",
    "    # Excluir arquivos específicos, se solicitado\n",
    "    if exclude_files:\n",
    "        for exclude_file in exclude_files:\n",
    "            exclude_path = os.path.join(dir_path, exclude_file)\n",
    "            if exclude_path in csv_files:\n",
    "                csv_files.remove(exclude_path)\n",
    "                print(f\"Arquivo excluído do processamento: {exclude_file}\")\n",
    "    \n",
    "    print(f\"Encontrados {len(csv_files)} arquivos para processar.\")\n",
    "    \n",
    "    # Se tabela não existe e create_if_not_exists=True, criar a tabela com base no primeiro arquivo\n",
    "    if not tabela_existe and create_if_not_exists and len(csv_files) > 0:\n",
    "        print(f\"Criando tabela '{table_name}' com base no primeiro arquivo...\")\n",
    "        sample_file = csv_files[0]\n",
    "        sample_df = read_csv_file(sample_file, sep=sep, encoding=encoding, date_columns=date_columns)\n",
    "        if sample_df is not None:\n",
    "            if create_table(conn, engine, table_name, sample_df):\n",
    "                tabela_existe = True\n",
    "    \n",
    "    # Processar cada arquivo\n",
    "    total_registros = 0\n",
    "    for file_path in csv_files:\n",
    "        print(f\"\\nProcessando arquivo: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Ler arquivo CSV\n",
    "        df = read_csv_file(file_path, sep=sep, encoding=encoding, date_columns=date_columns)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        # Mostrar amostra dos dados\n",
    "        print(\"\\nAmostra dos dados:\")\n",
    "        display(df.head(3))\n",
    "        \n",
    "        # Importar dados\n",
    "        success = import_data(df, engine, table_name, if_exists=if_exists)\n",
    "        if success:\n",
    "            total_registros += len(df)\n",
    "    \n",
    "    # Fechar conexão\n",
    "    conn.close()\n",
    "    print(f\"\\nProcesso concluído! Total de {total_registros} registros importados de {len(csv_files)} arquivos para a tabela '{table_name}'.\")\n",
    "    \n",
    "    return total_registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(conn, engine, table_name, sample_df=None):\n",
    "    \"\"\"Cria a tabela no banco de dados com base no DataFrame de amostra\"\"\"\n",
    "    try:\n",
    "        if sample_df is not None:\n",
    "            # Usar o DataFrame para criar a tabela com tipos adequados\n",
    "            # Limitamos a 0 registros para apenas criar a estrutura sem inserir dados\n",
    "            sample_df.head(0).to_sql(table_name, engine, if_exists='fail', index=False)\n",
    "            print(f\"Tabela '{table_name}' criada com sucesso baseada no schema do DataFrame!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Erro: DataFrame de amostra não fornecido para criação da tabela.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar tabela '{table_name}': {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de Uso - Importação de Prestadores\n",
    "\n",
    "Aqui está um exemplo de como usar a função para importar os prestadores não hospitalares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com PostgreSQL estabelecida com sucesso!\n",
      "Tabela 'cidades' existe: True\n",
      "Encontrados 0 arquivos para processar.\n",
      "\n",
      "Processo concluído! Total de 0 registros importados de 0 arquivos para a tabela 'cidades'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de importação de prestadores não hospitalares\n",
    "dir_prestadores = '/Volumes/M1_SSD/DEV/ANS/Arquivos/Cidades de Atuação/'\n",
    "dir_cidades = '/Volumes/M1_SSD/DEV/ANS/Arquivos/Cidades de Atuação/'\n",
    "#data_colunas_prestadores = [\n",
    "#    'DT_VINCULO_OPERADORA_INICIO', \n",
    "#    'DT_VINCULO_OPERADORA_FIM', \n",
    "#    'DT_ATUALIZACAO'\n",
    "#]\n",
    "#excluir_arquivos = ['opera_presta_nao_hospitalares_202502_RR.csv']\n",
    "\n",
    "\n",
    "importar_dados(\n",
    "    dir_path=dir_cidades,\n",
    "    file_pattern='cidades.csv',\n",
    "    table_name='cidades',\n",
    "    sep=',',  # Ajuste para usar vírgula como separador\n",
    "    if_exists='append'  # Use 'replace' para substituir a tabela ou 'fail' para falhar se a tabela existir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Outros Tipos de Dados\n",
    "\n",
    "Você pode criar células adicionais para importar outros tipos de dados, como demonstrado abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndir_outros_dados = '/Volumes/M1_SSD/DEV/ANS/Arquivos/outro_diretorio/'\\ndata_colunas_outros = [\\n    'DATA_INICIO', \\n    'DATA_FIM'\\n]\\n\\nimportar_dados(\\n    dir_path=dir_outros_dados,\\n    file_pattern='padrao_arquivo_*.csv',\\n    table_name='outra_tabela',\\n    date_columns=data_colunas_outros,\\n    if_exists='append'\\n)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo para importar outro tipo de dados (modifique conforme necessário)\n",
    "'''\n",
    "dir_outros_dados = '/Volumes/M1_SSD/DEV/ANS/Arquivos/outro_diretorio/'\n",
    "data_colunas_outros = [\n",
    "    'DATA_INICIO', \n",
    "    'DATA_FIM'\n",
    "]\n",
    "\n",
    "importar_dados(\n",
    "    dir_path=dir_outros_dados,\n",
    "    file_pattern='padrao_arquivo_*.csv',\n",
    "    table_name='outra_tabela',\n",
    "    date_columns=data_colunas_outros,\n",
    "    if_exists='append'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Dados Hospitalares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndir_hospitalares = '/Volumes/M1_SSD/DEV/ANS/Arquivos/prestadores/arquivos/operadoras_e_prestadores_hospitalares/'\\ndata_colunas_hospitalares = [\\n    'DT_VINCULO_OPERADORA_INICIO', \\n    'DT_VINCULO_OPERADORA_FIM', \\n    'DT_ATUALIZACAO'\\n]\\n\\nimportar_dados(\\n    dir_path=dir_hospitalares,\\n    file_pattern='opera_presta_hospitalares_*.csv',\\n    table_name='prestadores_hospitalares',\\n    date_columns=data_colunas_hospitalares,\\n    if_exists='append'\\n)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo para importar dados de prestadores hospitalares\n",
    "'''\n",
    "dir_hospitalares = '/Volumes/M1_SSD/DEV/ANS/Arquivos/prestadores/arquivos/operadoras_e_prestadores_hospitalares/'\n",
    "data_colunas_hospitalares = [\n",
    "    'DT_VINCULO_OPERADORA_INICIO', \n",
    "    'DT_VINCULO_OPERADORA_FIM', \n",
    "    'DT_ATUALIZACAO'\n",
    "]\n",
    "\n",
    "importar_dados(\n",
    "    dir_path=dir_hospitalares,\n",
    "    file_pattern='opera_presta_hospitalares_*.csv',\n",
    "    table_name='prestadores_hospitalares',\n",
    "    date_columns=data_colunas_hospitalares,\n",
    "    if_exists='append'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta para Verificar os Dados Importados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_tabela(table_name, limit=10):\n",
    "    \"\"\"Função para verificar os dados de uma tabela após a importação\"\"\"\n",
    "    conn = create_connection()\n",
    "    if not conn:\n",
    "        return\n",
    "    \n",
    "    engine = create_sqlalchemy_engine()\n",
    "    \n",
    "    try:\n",
    "        # Contar registros\n",
    "        count_query = f\"SELECT COUNT(*) FROM {table_name}\"\n",
    "        count = pd.read_sql(count_query, engine).iloc[0, 0]\n",
    "        print(f\"Tabela '{table_name}' contém {count} registros.\")\n",
    "        \n",
    "        # Mostrar amostra\n",
    "        sample_query = f\"SELECT * FROM {table_name} LIMIT {limit}\"\n",
    "        sample = pd.read_sql(sample_query, engine)\n",
    "        display(sample)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar a tabela: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Verificar a tabela de prestadores após a importação\n",
    "# verificar_tabela('prestadores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Cidades de Atuação/cidades.csv')\n",
    "\n",
    "# Get all column names\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "# Remove QT_HAB_MUNICIPIO from the columns to be quoted\n",
    "columns.remove('QT_HAB_MUNICIPIO')\n",
    "\n",
    "# Apply quotes to all string columns except QT_HAB_MUNICIPIO\n",
    "for column in columns:\n",
    "    df[column] = '\"' + df[column].astype(str) + '\"'\n",
    "\n",
    "# Save the modified dataframe back to CSV\n",
    "df.to_csv('/Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Cidades de Atuação/cidades.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando coleta da lista de operadoras em 2025-03-22 21:03:41...\n",
      "Coletando página 1...\n",
      "Informações de paginação: Página 1 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 1. Total até agora: 100\n",
      "Coletando página 2...\n",
      "Informações de paginação: Página 2 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 2. Total até agora: 200\n",
      "Coletando página 3...\n",
      "Informações de paginação: Página 3 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 3. Total até agora: 300\n",
      "Coletando página 4...\n",
      "Informações de paginação: Página 4 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 4. Total até agora: 400\n",
      "Coletando página 5...\n",
      "Informações de paginação: Página 5 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 5. Total até agora: 500\n",
      "Coletando página 6...\n",
      "Informações de paginação: Página 6 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 6. Total até agora: 600\n",
      "Coletando página 7...\n",
      "Informações de paginação: Página 7 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 7. Total até agora: 700\n",
      "Coletando página 8...\n",
      "Informações de paginação: Página 8 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 8. Total até agora: 800\n",
      "Coletando página 9...\n",
      "Informações de paginação: Página 9 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 9. Total até agora: 900\n",
      "Coletando página 10...\n",
      "Informações de paginação: Página 10 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 10. Total até agora: 1000\n",
      "Coletando página 11...\n",
      "Informações de paginação: Página 11 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 11. Total até agora: 1100\n",
      "Coletando página 12...\n",
      "Informações de paginação: Página 12 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 12. Total até agora: 1200\n",
      "Coletando página 13...\n",
      "Informações de paginação: Página 13 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 13. Total até agora: 1300\n",
      "Coletando página 14...\n",
      "Informações de paginação: Página 14 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 14. Total até agora: 1400\n",
      "Coletando página 15...\n",
      "Informações de paginação: Página 15 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 15. Total até agora: 1500\n",
      "Coletando página 16...\n",
      "Informações de paginação: Página 16 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 16. Total até agora: 1600\n",
      "Coletando página 17...\n",
      "Informações de paginação: Página 17 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 17. Total até agora: 1700\n",
      "Coletando página 18...\n",
      "Informações de paginação: Página 18 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 18. Total até agora: 1800\n",
      "Coletando página 19...\n",
      "Informações de paginação: Página 19 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 19. Total até agora: 1900\n",
      "Coletando página 20...\n",
      "Informações de paginação: Página 20 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 20. Total até agora: 2000\n",
      "Coletando página 21...\n",
      "Informações de paginação: Página 21 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 21. Total até agora: 2100\n",
      "Coletando página 22...\n",
      "Informações de paginação: Página 22 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 22. Total até agora: 2200\n",
      "Coletando página 23...\n",
      "Informações de paginação: Página 23 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 23. Total até agora: 2300\n",
      "Coletando página 24...\n",
      "Informações de paginação: Página 24 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 24. Total até agora: 2400\n",
      "Coletando página 25...\n",
      "Informações de paginação: Página 25 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 25. Total até agora: 2500\n",
      "Coletando página 26...\n",
      "Informações de paginação: Página 26 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 26. Total até agora: 2600\n",
      "Coletando página 27...\n",
      "Informações de paginação: Página 27 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 27. Total até agora: 2700\n",
      "Coletando página 28...\n",
      "Informações de paginação: Página 28 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 28. Total até agora: 2800\n",
      "Coletando página 29...\n",
      "Informações de paginação: Página 29 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 29. Total até agora: 2900\n",
      "Coletando página 30...\n",
      "Informações de paginação: Página 30 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 30. Total até agora: 3000\n",
      "Coletando página 31...\n",
      "Informações de paginação: Página 31 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 31. Total até agora: 3100\n",
      "Coletando página 32...\n",
      "Informações de paginação: Página 32 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 32. Total até agora: 3200\n",
      "Coletando página 33...\n",
      "Informações de paginação: Página 33 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 33. Total até agora: 3300\n",
      "Coletando página 34...\n",
      "Informações de paginação: Página 34 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 34. Total até agora: 3400\n",
      "Coletando página 35...\n",
      "Informações de paginação: Página 35 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 35. Total até agora: 3500\n",
      "Coletando página 36...\n",
      "Informações de paginação: Página 36 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 36. Total até agora: 3600\n",
      "Coletando página 37...\n",
      "Informações de paginação: Página 37 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 37. Total até agora: 3700\n",
      "Coletando página 38...\n",
      "Informações de paginação: Página 38 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 38. Total até agora: 3800\n",
      "Coletando página 39...\n",
      "Informações de paginação: Página 39 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 39. Total até agora: 3900\n",
      "Coletando página 40...\n",
      "Informações de paginação: Página 40 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 40. Total até agora: 4000\n",
      "Coletando página 41...\n",
      "Informações de paginação: Página 41 de -1, Total de elementos: -1\n",
      "Coletados 100 registros da página 41. Total até agora: 4100\n",
      "Coletando página 42...\n",
      "Informações de paginação: Página 42 de -1, Total de elementos: -1\n",
      "Coletados 23 registros da página 42. Total até agora: 4123\n",
      "Última página alcançada.\n",
      "Coleta da lista básica finalizada. Total de 4123 operadoras.\n",
      "Lista básica salva em: /Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras/ans_operadoras_lista_basica_20250322_210341.csv\n",
      "Obtidos 4123 registros ANS para busca detalhada.\n",
      "Iniciando coleta de detalhes de cada operadora em 2025-03-22 21:04:28...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 50/4123 registros (1.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 100/4123 registros (2.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 150/4123 registros (3.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 200/4123 registros (4.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 250/4123 registros (6.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 300/4123 registros (7.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 350/4123 registros (8.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 400/4123 registros (9.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 450/4123 registros (10.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 500/4123 registros (12.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 550/4123 registros (13.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 600/4123 registros (14.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 650/4123 registros (15.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 700/4123 registros (17.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 750/4123 registros (18.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 800/4123 registros (19.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 850/4123 registros (20.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 900/4123 registros (21.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 950/4123 registros (23.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1000/4123 registros (24.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1050/4123 registros (25.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1100/4123 registros (26.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1150/4123 registros (27.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1200/4123 registros (29.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1250/4123 registros (30.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1300/4123 registros (31.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1350/4123 registros (32.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1400/4123 registros (34.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1450/4123 registros (35.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1500/4123 registros (36.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1550/4123 registros (37.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1600/4123 registros (38.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1650/4123 registros (40.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1700/4123 registros (41.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1750/4123 registros (42.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1800/4123 registros (43.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1850/4123 registros (44.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1900/4123 registros (46.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 1950/4123 registros (47.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2000/4123 registros (48.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro na requisição para operadora 400165: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2050/4123 registros (49.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2100/4123 registros (50.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2150/4123 registros (52.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2200/4123 registros (53.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2250/4123 registros (54.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2300/4123 registros (55.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2350/4123 registros (57.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2400/4123 registros (58.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2450/4123 registros (59.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2500/4123 registros (60.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2550/4123 registros (61.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2600/4123 registros (63.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2650/4123 registros (64.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2700/4123 registros (65.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2750/4123 registros (66.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2800/4123 registros (67.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2850/4123 registros (69.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2900/4123 registros (70.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 2950/4123 registros (71.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3000/4123 registros (72.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3050/4123 registros (74.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3100/4123 registros (75.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3150/4123 registros (76.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3200/4123 registros (77.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3250/4123 registros (78.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3300/4123 registros (80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3350/4123 registros (81.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3400/4123 registros (82.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3450/4123 registros (83.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3500/4123 registros (84.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3550/4123 registros (86.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3600/4123 registros (87.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3650/4123 registros (88.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3700/4123 registros (89.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3750/4123 registros (91.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3800/4123 registros (92.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3850/4123 registros (93.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3900/4123 registros (94.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 3950/4123 registros (95.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 4000/4123 registros (97.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 4050/4123 registros (98.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processados 4100/4123 registros (99.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coletando detalhes: 100%|██████████| 4123/4123 [42:37<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coleta de detalhes finalizada. Obtidos detalhes de 4122 operadoras.\n",
      "\n",
      "DataFrame criado com sucesso. Dimensões: (4122, 34)\n",
      "\n",
      "Colunas disponíveis:\n",
      "- registro_ans\n",
      "- cnpj\n",
      "- razao_social\n",
      "- nome_fantasia\n",
      "- ativa\n",
      "- email\n",
      "- site\n",
      "- representante_nome\n",
      "- representante_cargo\n",
      "- autorizacao_funcionamento_em\n",
      "- concessao_registro_definitivo_em\n",
      "- registrada_em\n",
      "- descredenciada_em\n",
      "- descredenciamento_motivo\n",
      "- classificacao_sigla\n",
      "- classificacao_nome\n",
      "- endereco_logradouro\n",
      "- endereco_numero\n",
      "- endereco_complemento\n",
      "- endereco_bairro\n",
      "- endereco_cep\n",
      "- endereco_municipio_codigo\n",
      "- endereco_municipio_nome\n",
      "- endereco_uf_sigla\n",
      "- endereco_valido\n",
      "- telefone_ddd\n",
      "- telefone_numero\n",
      "- fax_ddd\n",
      "- fax_numero\n",
      "- link_self_href\n",
      "- link_operadoras_href\n",
      "- link_operadoras_templated\n",
      "- segmentacao_sigla\n",
      "- segmentacao_nome\n",
      "\n",
      "Dados detalhados salvos em: /Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras/ans_operadoras_detalhadas_20250322_210341.csv\n",
      "Dados detalhados também salvos em Excel: /Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras/ans_operadoras_detalhadas_20250322_210341.xlsx\n",
      "\n",
      "Estatísticas: 1107 operadoras ativas e 3015 inativas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm  # Versão padrão do tqdm em vez da versão notebook\n",
    "\n",
    "# URL base da API\n",
    "base_url = 'https://www.ans.gov.br/operadoras-entity/v1/operadoras'\n",
    "\n",
    "# Diretório para salvar os dados\n",
    "output_dir = \"/Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras\"\n",
    "# Criar o diretório se não existir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Timestamp para os arquivos\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Função para coletar todas as operadoras (lista básica)\n",
    "def get_all_operadoras():\n",
    "    print(f\"Iniciando coleta da lista de operadoras em {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
    "    \n",
    "    # Parâmetros iniciais\n",
    "    params = {\n",
    "        'size': 100,  # Máximo de registros por página\n",
    "        'sort': 'registro_ans',\n",
    "        'page': 0\n",
    "    }\n",
    "    \n",
    "    all_records = []\n",
    "    page = 0\n",
    "    more_pages = True\n",
    "    total_records = 0\n",
    "    \n",
    "    while more_pages:\n",
    "        params['page'] = page\n",
    "        print(f\"Coletando página {page+1}...\")\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                \n",
    "                # Verifica o formato da resposta\n",
    "                if isinstance(data, dict) and 'content' in data:\n",
    "                    records = data['content']\n",
    "                    total_pages = data.get('totalPages', -1)\n",
    "                    total_elements = data.get('totalElements', -1)\n",
    "                    print(f\"Informações de paginação: Página {page+1} de {total_pages}, Total de elementos: {total_elements}\")\n",
    "                elif isinstance(data, list):\n",
    "                    records = data\n",
    "                else:\n",
    "                    print(f\"Estrutura de dados inesperada. Verificando primeira parte...\")\n",
    "                    print(str(data)[:500])\n",
    "                    break\n",
    "                \n",
    "                num_records = len(records)\n",
    "                \n",
    "                if num_records == 0:\n",
    "                    more_pages = False\n",
    "                    print(\"Nenhum registro encontrado na página. Finalizando coleta.\")\n",
    "                    break\n",
    "                    \n",
    "                all_records.extend(records)\n",
    "                total_records += num_records\n",
    "                \n",
    "                print(f\"Coletados {num_records} registros da página {page+1}. Total até agora: {total_records}\")\n",
    "                \n",
    "                # Se retornou menos registros que o tamanho da página, é a última página\n",
    "                if num_records < params['size']:\n",
    "                    more_pages = False\n",
    "                    print(\"Última página alcançada.\")\n",
    "                    break\n",
    "                    \n",
    "                page += 1\n",
    "                time.sleep(1)  # Pausa para não sobrecarregar a API\n",
    "                \n",
    "            else:\n",
    "                print(f\"Erro na requisição. Status code: {response.status_code}\")\n",
    "                print(f\"Resposta: {response.text}\")\n",
    "                more_pages = False\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar a página {page+1}: {str(e)}\")\n",
    "            more_pages = False\n",
    "            break\n",
    "    \n",
    "    print(f\"Coleta da lista básica finalizada. Total de {len(all_records)} operadoras.\")\n",
    "    return all_records\n",
    "\n",
    "# Função para obter detalhes de uma operadora específica\n",
    "def get_operadora_details(registro_ans):\n",
    "    url = f\"{base_url}/{registro_ans}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Erro ao obter detalhes da operadora {registro_ans}. Status: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na requisição para operadora {registro_ans}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Função principal\n",
    "def main():\n",
    "    # 1. Obter a lista de todas as operadoras\n",
    "    operadoras_lista = get_all_operadoras()\n",
    "    \n",
    "    if not operadoras_lista:\n",
    "        print(\"Nenhuma operadora encontrada.\")\n",
    "        return\n",
    "    \n",
    "    # Salvar a lista básica (caso a próxima etapa falhe)\n",
    "    basic_df = pd.DataFrame(operadoras_lista)\n",
    "    basic_file = f\"{output_dir}/ans_operadoras_lista_basica_{timestamp}.csv\"\n",
    "    basic_df.to_csv(basic_file, index=False, encoding='utf-8')\n",
    "    print(f\"Lista básica salva em: {basic_file}\")\n",
    "    \n",
    "    # Extrair os registros ANS para buscar detalhes\n",
    "    registros_ans = []\n",
    "    for operadora in operadoras_lista:\n",
    "        if 'registro_ans' in operadora:\n",
    "            registros_ans.append(operadora['registro_ans'])\n",
    "    \n",
    "    print(f\"Obtidos {len(registros_ans)} registros ANS para busca detalhada.\")\n",
    "    \n",
    "    # 2. Obter detalhes de cada operadora\n",
    "    print(f\"Iniciando coleta de detalhes de cada operadora em {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
    "    \n",
    "    operadoras_detalhadas = []\n",
    "    \n",
    "    # Salvar também os JSONs individuais para cada operadora\n",
    "    json_dir = f\"{output_dir}/json_operadoras_{timestamp}\"\n",
    "    os.makedirs(json_dir, exist_ok=True)\n",
    "    \n",
    "    # Contador simples para mostrar progresso\n",
    "    total_registros = len(registros_ans)\n",
    "    \n",
    "    # Usar tqdm padrão para mostrar barra de progresso\n",
    "    for i, registro in enumerate(tqdm(registros_ans, desc=\"Coletando detalhes\")):\n",
    "        details = get_operadora_details(registro)\n",
    "        \n",
    "        if details:\n",
    "            # Salvar o JSON individual\n",
    "            with open(f\"{json_dir}/{registro}.json\", 'w', encoding='utf-8') as f:\n",
    "                json.dump(details, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # Tratar \"_links\" que é um objeto aninhado\n",
    "            if '_links' in details:\n",
    "                # Transformar links em colunas planas\n",
    "                for link_key, link_value in details['_links'].items():\n",
    "                    prefix = f\"link_{link_key}_\"\n",
    "                    for k, v in link_value.items():\n",
    "                        details[prefix + k] = v\n",
    "                # Remover o objeto original\n",
    "                del details['_links']\n",
    "            \n",
    "            operadoras_detalhadas.append(details)\n",
    "        \n",
    "        # Log periódico para acompanhar o progresso (a cada 50 operadoras)\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processados {i + 1}/{total_registros} registros ({(i + 1)/total_registros*100:.1f}%)\")\n",
    "        \n",
    "        # Pausa para não sobrecarregar a API\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print(f\"Coleta de detalhes finalizada. Obtidos detalhes de {len(operadoras_detalhadas)} operadoras.\")\n",
    "    \n",
    "    # 3. Converter para DataFrame e salvar\n",
    "    if operadoras_detalhadas:\n",
    "        df_detalhado = pd.DataFrame(operadoras_detalhadas)\n",
    "        \n",
    "        # Exibir informações\n",
    "        print(f\"\\nDataFrame criado com sucesso. Dimensões: {df_detalhado.shape}\")\n",
    "        print(\"\\nColunas disponíveis:\")\n",
    "        for col in df_detalhado.columns:\n",
    "            print(f\"- {col}\")\n",
    "        \n",
    "        # Salvar CSV completo\n",
    "        output_file = f\"{output_dir}/ans_operadoras_detalhadas_{timestamp}.csv\"\n",
    "        df_detalhado.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        print(f\"\\nDados detalhados salvos em: {output_file}\")\n",
    "        \n",
    "        # Salvar também em Excel para manter formatação\n",
    "        excel_file = f\"{output_dir}/ans_operadoras_detalhadas_{timestamp}.xlsx\"\n",
    "        df_detalhado.to_excel(excel_file, index=False)\n",
    "        print(f\"Dados detalhados também salvos em Excel: {excel_file}\")\n",
    "        \n",
    "        # Informações adicionais\n",
    "        if 'ativa' in df_detalhado.columns:\n",
    "            ativas = df_detalhado['ativa'].sum() if df_detalhado['ativa'].dtype == 'bool' else df_detalhado['ativa'].astype(bool).sum()\n",
    "            print(f\"\\nEstatísticas: {ativas} operadoras ativas e {len(df_detalhado) - ativas} inativas\")\n",
    "    else:\n",
    "        print(\"Não foi possível obter dados detalhados das operadoras.\")\n",
    "\n",
    "# Executar o programa\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras/Relatorio_cadop_canceladas.csv', sep=\";\")\n",
    "\n",
    "# Add new column 'Ativa' with value 'Cancelada' for all rows\n",
    "df['Ativa'] = 'Cancelada'\n",
    "\n",
    "# Save the modified dataframe back to CSV\n",
    "df.to_csv('/Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras/Relatorio_cadop_canceladas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras/Relatorio_cadop.csv', sep=\";\")\n",
    "\n",
    "# Add new column 'Ativa' with value 'Cancelada' for all rows\n",
    "df['Ativa'] = 'Ativa'\n",
    "\n",
    "# Save the modified dataframe back to CSV\n",
    "df.to_csv('/Volumes/M1_SSD/DEV/ANS/Arquivos/dados/Operadoras/Relatorio_cadop.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junte os dois arqtuivos csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
